# Veridion_Company_Classifier_TASK
Given the nature of this task, there are multiple ways to solve it, each implying a different degree of performance and requirements. When exploring those options, I considered the following approaches: pure rules / keyword lists; classical ML algorithms such as TF-IDF + Logistic-Regression,  SVM and LightGBM; Dense-embedding nearest-neighbor; zero/few shot LLM and LLM-RAG hybrid. Given the absence of the training data and the uncertainty of creating myself, through all means I could think of, a qualitative training dataset, the classical ML algorithms such as TF-IDF + Logistic-Regression,  SVM and LightGBM, and Dense-embedding nearest-neighbor options have been dropped. Moreover, due to the overall low performance presented by pure rules / keyword lists option, this idea was dropped as well.
	Given this situation, I decided to investigate the zero/few shot LLM option. In my search for a well-suited pretrained LLM, i have excluded any paid subscription LLM for 2 reasons: 1/ If this script where to be created for a company, the goal would be to find a method as accurate as possible, with a fitting size and processing speed, which costs as less as possible. 2/ I happen to have a very small budget allocated for this project. As such, I began to research some of the best free LLMs on the market, the LLama models. Given my computational limitations, boosting an RTX 3070 GPU with 8 GB of VRAM and 16 GB of RAM, I was able to integrate a mediocre model, more specifically the llama3-8b Instruct 4 bit variant. 
	At first i tried a zero-shot approach but the model was heavily hallucinating, retrieving taxonomy labels from multiple parts of the fed prompt, not only from the integrated taxonomy list. As such, after multiple failed attempts with different zero-shot prompt styles, I have changed my approach to few-shot. With this change, the hallucinations stopped but another problem appeared, more specifically, many companies where receiving no taxonomy labels as the model couldn't decide  what label to assign. Given my situation which did not allow the employment of a better model, I decided to change my approach to a LLM-RAG hybrid, employing an embedding model, particularly MiniLM L6 v2, to feed into the main model, for each company, the top K most probable taxonomy labels. Moreover, for each company i have implemented a 3 beam approach, effectively instructing the LLM to do 3 predictions for each company, thus creating a bigger predicted taxonomy label pool. Those changes allowed for more companies to receive their taxonomy labels but it did not fully mitigate the problem. As such, where the main model could not decide the taxonomy label, the first taxonomy label from the top K most probable labels would be assigned.
	Moreover, to extract the labels from the LLM response, a parser function was created to extract all predicted taxonomy labels, using regular expressions. Despite this, the answers provided by the LLama model could sometimes cause errors despite the parser function and thus I had to implement a custom logits processor in order to better shape the answers of the LLM. Also for this problem, I have discovered that by turning the sampling process off, the responses would follow a more concrete structure and the predicted labels would be more trustworthy. 
	In order to boost the model's accuracy, for the companies where it could predict at least 1 label, I implemented a majority vote, effectively choosing the most prominent labels.
	To further boost the performance of this entire process, both models should be changed to more performing ones. And the good news is that more performing free LLMs exist, quiet a few in fact.
	The performance of my approach was calculated through recall, precision and f1 scores, against the same list filled with taxonomy labels by one of the most performing LLM of today, ChatGPT O3 model. 
 Recall: 48%
 Precision: 20%
 F1: 28%
 As a final word, compared to the other options, using an LLM, by itself or combined with other enhancements/approaches, for this task is the best way to solve this problem most accurately, due to the fact that an LLM, if created correctly, can see more complex patterns within the data compared to the other approaches and thus better predict more complexly described companies.
